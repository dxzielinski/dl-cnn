{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    \n",
    "from model_utils import ModelKANCNN, ClassificationData, no_augmentation\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "L.seed_everything(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "KAN_Convolutional_Layer.__init__() got an unexpected keyword argument 'n_convs'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m example_hyperparams = {\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0.1\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m128\u001b[39m,\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mweight_decay\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0.001\u001b[39m,\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdropout\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0.2\u001b[39m,\n\u001b[32m      6\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model = \u001b[43mModelKANCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexample_hyperparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexample_hyperparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlearning_rate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexample_hyperparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexample_hyperparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdropout\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m logger = MLFlowLogger(save_dir=\u001b[33m\"\u001b[39m\u001b[33mmlruns\u001b[39m\u001b[33m\"\u001b[39m, experiment_name=\u001b[33m\"\u001b[39m\u001b[33mKAN-CNN\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m early_stop = EarlyStopping(monitor=\u001b[33m\"\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m\"\u001b[39m, patience=\u001b[32m3\u001b[39m, mode=\u001b[33m\"\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m\"\u001b[39m, verbose=\u001b[38;5;28;01mTrue\u001b[39;00m, min_delta=\u001b[32m0.01\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SPCX\\Desktop\\github-repositories\\dl-cnn\\model\\model_utils.py:351\u001b[39m, in \u001b[36mModelKANCNN.__init__\u001b[39m\u001b[34m(self, batch_size, learning_rate, dropout, weight_decay)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    341\u001b[39m     \u001b[38;5;28mself\u001b[39m, batch_size=\u001b[32m64\u001b[39m, learning_rate=\u001b[32m0.01\u001b[39m, dropout=\u001b[32m0.2\u001b[39m, weight_decay=\u001b[32m0.001\u001b[39m\n\u001b[32m    342\u001b[39m ):\n\u001b[32m    343\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    344\u001b[39m         hyperparameters={\n\u001b[32m    345\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m\"\u001b[39m: learning_rate,\n\u001b[32m   (...)\u001b[39m\u001b[32m    349\u001b[39m         }\n\u001b[32m    350\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[43mKANCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SPCX\\Desktop\\github-repositories\\dl-cnn\\model\\model_utils.py:304\u001b[39m, in \u001b[36mKANCNN.__init__\u001b[39m\u001b[34m(self, dropout)\u001b[39m\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dropout):\n\u001b[32m    302\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m    303\u001b[39m     \u001b[38;5;28mself\u001b[39m.layers = torch.nn.Sequential(\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m         \u001b[43mKAN_Convolutional_Layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m            \u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m            \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m            \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_convs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    311\u001b[39m         torch.nn.BatchNorm2d(\u001b[32m32\u001b[39m),\n\u001b[32m    312\u001b[39m         torch.nn.ReLU(),\n\u001b[32m    313\u001b[39m         torch.nn.MaxPool2d(\u001b[32m2\u001b[39m),\n\u001b[32m    314\u001b[39m         KAN_Convolutional_Layer(\n\u001b[32m    315\u001b[39m             in_channels=\u001b[32m32\u001b[39m,\n\u001b[32m    316\u001b[39m             out_channels=\u001b[32m64\u001b[39m,\n\u001b[32m    317\u001b[39m             kernel_size=(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m),\n\u001b[32m    318\u001b[39m             stride=(\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m),\n\u001b[32m    319\u001b[39m             n_convs=\u001b[32m1\u001b[39m,\n\u001b[32m    320\u001b[39m         ),\n\u001b[32m    321\u001b[39m         torch.nn.BatchNorm2d(\u001b[32m64\u001b[39m),\n\u001b[32m    322\u001b[39m         torch.nn.ReLU(),\n\u001b[32m    323\u001b[39m         torch.nn.MaxPool2d(\u001b[32m2\u001b[39m),\n\u001b[32m    324\u001b[39m         torch.nn.Flatten(),\n\u001b[32m    325\u001b[39m         torch.nn.Linear(\n\u001b[32m    326\u001b[39m             in_features=\u001b[32m64\u001b[39m * _calc_conv_output_size(_calc_conv_output_size()) ** \u001b[32m2\u001b[39m,\n\u001b[32m    327\u001b[39m             out_features=\u001b[32m64\u001b[39m,\n\u001b[32m    328\u001b[39m         ),\n\u001b[32m    329\u001b[39m         torch.nn.BatchNorm1d(\u001b[32m64\u001b[39m),\n\u001b[32m    330\u001b[39m         torch.nn.ReLU(),\n\u001b[32m    331\u001b[39m         torch.nn.Dropout(dropout),\n\u001b[32m    332\u001b[39m         torch.nn.Linear(in_features=\u001b[32m64\u001b[39m, out_features=\u001b[32m10\u001b[39m),\n\u001b[32m    333\u001b[39m     )\n",
      "\u001b[31mTypeError\u001b[39m: KAN_Convolutional_Layer.__init__() got an unexpected keyword argument 'n_convs'"
     ]
    }
   ],
   "source": [
    "example_hyperparams = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"batch_size\": 128,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"dropout\": 0.2,\n",
    "}\n",
    "model = ModelKANCNN(batch_size=example_hyperparams[\"batch_size\"], learning_rate=example_hyperparams[\"learning_rate\"], weight_decay=example_hyperparams[\"weight_decay\"], dropout=example_hyperparams[\"dropout\"])\n",
    "logger = MLFlowLogger(save_dir=\"mlruns\", experiment_name=\"KAN-CNN\")\n",
    "early_stop = EarlyStopping(monitor=\"train_loss\", patience=3, mode=\"min\", verbose=True, min_delta=0.01)\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"val_f1_macro\", mode=\"max\", dirpath=\"checkpoints/kan\", filename=f\"lr={model.hyperparameters[\"learning_rate\"]}_bs={model.hyperparameters[\"batch_size\"]}_wd={model.hyperparameters[\"weight_decay\"]}_dropout={model.hyperparameters[\"dropout\"]}\" + \"-{epoch:02d}-{val_f1_macro:.2f}\")\n",
    "trainer = L.Trainer(max_epochs=20, logger=logger, num_sanity_val_steps=0, enable_model_summary=False, deterministic=False, callbacks=[early_stop, checkpoint_callback], precision=\"16-mixed\")\n",
    "data = ClassificationData(batch_size=model.hyperparameters[\"batch_size\"])\n",
    "trainer.fit(model, datamodule=data)\n",
    "trainer.test(model, datamodule=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelKANCNN(example_hyperparams)\n",
    "logger = MLFlowLogger(save_dir=\"mlruns\", experiment_name=\"KAN-CNN-no-augmentation\")\n",
    "early_stop = EarlyStopping(monitor=\"train_loss\", patience=3, mode=\"min\", verbose=True, min_delta=0.01)\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"val_f1_macro\", mode=\"max\", dirpath=\"checkpoints/kan\", filename=f\"no-augment_lr={model.hyperparameters[\"learning_rate\"]}_bs={model.hyperparameters[\"batch_size\"]}_wd={model.hyperparameters[\"weight_decay\"]}_dropout={model.hyperparameters[\"dropout\"]}\" + \"-{epoch:02d}-{val_f1_macro:.2f}\")\n",
    "trainer = L.Trainer(max_epochs=20, logger=logger, num_sanity_val_steps=0, enable_model_summary=False, deterministic=False, callbacks=[early_stop, checkpoint_callback], precision=\"16-mixed\")\n",
    "data = ClassificationData(batch_size=model.hyperparameters[\"batch_size\"], transform=no_augmentation)\n",
    "trainer.fit(model, datamodule=data)\n",
    "trainer.test(model, datamodule=data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
